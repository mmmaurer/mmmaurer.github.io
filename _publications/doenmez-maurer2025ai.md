---
title: "AI Argues Differently: Distinct Argumentative and Linguistic Patterns of LLMs in Persuasive Contexts"
collection: publications
category: conferences
permalink: /publication/ai-argues-differently
excerpt: 'This paper investigates how the argumentative and linguistic patterns of large language models (LLMs) differ from those of humans in persuasive contexts. It shows that LLM-written arguments exhibit distinct characteristics and can be identified relatively easily using logistic regression with argument quality or linguistic features.'
date: 2025-11-01
venue: 'Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025)'
paperurl: 'https://aclanthology.org/2025.emnlp-main.1755/'
citation: 'Esra Dönmez, Maximilian Maurer, Gabriella Lapesa, and Agnieszka Falenska. 2025. AI Argues Differently: Distinct Argumentative and Linguistic Patterns of LLMs in Persuasive Contexts. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pages 34583–34614, Suzhou, China. Association for Computational Linguistics.'
---

# Abstract
Distinguishing LLM-generated text from human-written is a key challenge for safe and ethical NLP, particularly in high-stake settings such as persuasive online discourse. While recent work focuses on detection, real-world use cases also demand interpretable tools to help humans understand and distinguish LLM-generated texts. To this end, we present an analysis framework comparing human- and LLM-authored arguments using two easily-interpretable feature sets: general-purpose linguistic features (e.g., lexical richness, syntactic complexity) and domain-specific features related to argument quality (e.g., logical soundness, engagement strategies). Applied to */r/ChangeMyView* arguments by humans and three LLMs, our method reveals clear patterns: LLM-generated counter-arguments show lower type-token and lemma-token ratios but higher emotional intensity — particularly in anticipation and trust. They more closely resemble textbook-quality arguments — cogent, justified, explicitly respectful toward others, and positive in tone. Moreover, counter-arguments generated by LLMs converge more closely with the original post’s style and quality than those written by humans. Finally, we demonstrate that these differences enable a lightweight, interpretable, and highly effective classifier for detecting LLM-generated comments in CMV.
